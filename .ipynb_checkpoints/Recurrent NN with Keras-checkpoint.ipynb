{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sequences: data that is sort of \"interconnected\" and their sequence form meaning: like audio, video, text...\n",
    "using a classical neural network to take or output recurrent data is limiting since it will force us to abide by some size constraints on the input and output. Therefore, we use recurrent neural networks.\n",
    "\n",
    "Our objective is to make a neural net that can perform sum operations. We first need it to train to extract meaning out of literals, and then learn how to sum them up.\n",
    "\n",
    "Input is a tensor. (Matrices are 2D tensors) Tensors can represent data in any dimension.\n",
    "\n",
    "We will convert our data into one-hot encoding vectors.\n",
    "\n",
    "Model parts \n",
    "(1) encoder: takes the data and outputs a single vector representation of the data through a single SimpleRNN layer with a number of hidden units. It is fed into the...\n",
    "(2) decoder: \n",
    "\n",
    "\n",
    "\" To achieve this single vector representation of the entire input, we will use the RepeatVector layer and specify the number of times it should repeat. \"\n",
    "\n",
    "repeat layers reshapes the data: \n",
    "dense layer: layers of neurons are connected and this is the layer that outputs the predicted sequence - follows LSTM layers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#input should be a string, and output should be a string prediction too.\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import TimeDistributed, Dense, Dropout, SimpleRNN, RepeatVector\n",
    "from tensorflow.keras.callbacks import EarlyStopping, LambdaCallback\n",
    "from termcolor import colored"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, '0'), (1, '1'), (2, '2'), (3, '3'), (4, '4'), (5, '5'), (6, '6'), (7, '7'), (8, '8'), (9, '9'), (10, '+')]\n",
      "If chars are the keys then our dictionary is: {'0': 0, '1': 1, '2': 2, '3': 3, '4': 4, '5': 5, '6': 6, '7': 7, '8': 8, '9': 9, '+': 10}\n",
      "If indexes are the keys then our dictionary is: {0: '0', 1: '1', 2: '2', 3: '3', 4: '4', 5: '5', 6: '6', 7: '7', 8: '8', 9: '9', 10: '+'}\n"
     ]
    }
   ],
   "source": [
    "#to generate our data, we willneed to see all the possible constituents of the sequence: 0 to 9 and a +.\n",
    "\n",
    "\"\"\"\n",
    "some notes:\n",
    "(1) enumerate takes a list or string and outputs the index and its associated entry\n",
    "\"\"\"\n",
    "\n",
    "possible_chars = \"0123456789+\"\n",
    "\n",
    "print(list(enumerate(possible_chars)))\n",
    "\n",
    "char_to_index = dict((c,i) for i,c in enumerate(possible_chars))\n",
    "index_to_char = dict((i,c) for i,c in enumerate(possible_chars))\n",
    "\n",
    "print(\"If chars are the keys then our dictionary is:\",char_to_index)\n",
    "print(\"If indexes are the keys then our dictionary is:\",index_to_char)\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "now our inputs cannot be just string - we need to do some data preprocessing. RNN's expect tensors as input! We will\n",
    "(1) do one-hot-encoding for each possible character - therefore, we will have 10 features.\n",
    "(2) our input will be a bunch of vectors of length 10, each representing a character in the input.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('49+51', '100')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#let's create a function to generate our data.\n",
    "\n",
    "def generate_data():\n",
    "    op1 = np.random.randint(0,100)\n",
    "    op2 = np.random.randint(0,100)\n",
    "    \n",
    "    x = str(op1) + \"+\" + str(op2)\n",
    "    label = str(op1+op2)\n",
    "    \n",
    "    return x,label\n",
    "    \n",
    "generate_data()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "simple_rnn_2 (SimpleRNN)     (None, 128)               17920     \n",
      "_________________________________________________________________\n",
      "repeat_vector_1 (RepeatVecto (None, 5, 128)            0         \n",
      "_________________________________________________________________\n",
      "simple_rnn_3 (SimpleRNN)     (None, 5, 128)            32896     \n",
      "_________________________________________________________________\n",
      "time_distributed (TimeDistri (None, 5, 11)             1419      \n",
      "=================================================================\n",
      "Total params: 52,235\n",
      "Trainable params: 52,235\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#now we develop our model.\n",
    "\n",
    "#typical neural networks: would pad the input to make the size fixed AND would only test for \n",
    "#detection of tokens NOT the order in which they're linked. \n",
    "\n",
    "#example: not terrible - test for +ve and -ve connotations\n",
    "\n",
    "#keras is a high level API that uses tensorflow for its backend.\n",
    "\n",
    "#simple RNN layer: a fully connected layer whose outputs are fed back into the network - uses tanh for activation\n",
    "\n",
    "hidden_units = 128 \n",
    "max_time_steps = 5 #first operand (2) + plus sign (1) + second operand (2)\n",
    "\n",
    "model = Sequential([\n",
    "    #this layer expects inputs of no defined numbers of rows (flexible tensor size) but each consituent would have a size of 10\n",
    "    #to reflect one-hot-encoding of a single character.\n",
    "    #Purpose: outputs the \"context vector\" - we have taken an input, but how does each part of the input \"relate\"?\n",
    "    SimpleRNN(hidden_units, input_shape=(None, len(possible_chars))), \n",
    "    #to be able to take this context vector for each time step, we would need to duplicate it for the next layer to\n",
    "    #have a context vector for each time step. \n",
    "    RepeatVector(max_time_steps),\n",
    "    #now we do the decoder part of the architecture.\n",
    "    #the first thing to do is to take this context vectors and, based on them, generate some output sequence. The output will \n",
    "    #be the probabilities for various characters  @each time step.\n",
    "    SimpleRNN(hidden_units, return_sequences = True),\n",
    "    TimeDistributed(Dense(len(possible_chars),activation='softmax'))\n",
    "])\n",
    "\n",
    "model.compile(loss = 'categorical_crossentropy', #used with classification\n",
    "              optimizer = 'adam',\n",
    "              metrics=['accuracy'] #what to care for when training\n",
    "             )\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1+70 71\n",
      "[[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]] [[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "#we vectorize and devectorize our examples.\n",
    "\n",
    "def vectorize_example(x,y):\n",
    "    #initialize the vector versions of the input and output.\n",
    "    label = np.zeros((max_time_steps,len(possible_chars)))\n",
    "    example = np.zeros((max_time_steps,len(possible_chars)))\n",
    "    \n",
    "    #we fill our vector such that we pad with 0s from the beginning.\n",
    "    start_x = max_time_steps -len(x)\n",
    "    start_y = max_time_steps -len(y)\n",
    "    \n",
    "    #one-hot-encoding of our characters\n",
    "    for(i,c) in enumerate(x): \n",
    "        example[i+start_x,char_to_index.get(c)] = 1\n",
    "        \n",
    "    #pad with 0's at start\n",
    "    k = 0\n",
    "    while(k<start_x):\n",
    "        example[k,char_to_index.get('0')] = 1\n",
    "        k=k+1\n",
    "        \n",
    "       #one-hot-encoding of our characters\n",
    "    for(i,c) in enumerate(y): \n",
    "        label[i+start_y,char_to_index.get(c)] = 1\n",
    "        \n",
    "    #pad with 0's at start\n",
    "    ll = 0\n",
    "    while(ll<start_y):\n",
    "        label[ll,char_to_index.get('0')] = 1\n",
    "        ll=ll+1\n",
    "        \n",
    "    return example,label\n",
    "\n",
    "e, l = generate_data()\n",
    "print(e,l)\n",
    "ev, lv = vectorize_example(e,l)\n",
    "print(ev, lv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "01+70\n"
     ]
    }
   ],
   "source": [
    "def devectorize_example(example, label):\n",
    "    string_example = \"\"\n",
    "    string_label = \"\"\n",
    "    \n",
    "    for i in range(example.shape[0]):\n",
    "        for j in range(example.shape[1]):\n",
    "            if(example[i][j] == 1):\n",
    "                string_example = string_example + index_to_char.get(j)\n",
    "    \n",
    "    for i in range(label.shape[0]):\n",
    "        for j in range(label.shape[1]):\n",
    "            if(label[i][j] == 1):\n",
    "                string_label = string_label + index_to_char.get(j)\n",
    "    \n",
    "    return string_example,string_label    \n",
    "    \n",
    "\n",
    "#checking...\n",
    "\n",
    "string_example, string_label = devectorize_example(ev,lv)\n",
    "print(string_example)\n",
    "\n",
    "\n",
    "\n",
    "def devectorize_example(example):\n",
    "    result = [index_to_char[np.argmax(vec)] for i, vec in enumerate(example)]\n",
    "    return ''.join(result)\n",
    "\n",
    "devectorize_example(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2000, 5, 11) (2000, 5, 11)\n",
      "039+9\n",
      "00048\n"
     ]
    }
   ],
   "source": [
    "def create_dataset(num_examples = 2000):\n",
    "    x = np.zeros((num_examples,max_time_steps, len(possible_chars)))\n",
    "    y = np.zeros((num_examples,max_time_steps, len(possible_chars)))\n",
    "    \n",
    "    for i in range(num_examples):\n",
    "        e,l = generate_data()\n",
    "        ev, lv = vectorize_example(e,l)\n",
    "        x[i] = ev\n",
    "        y[i] = lv\n",
    "    return x,y\n",
    "\n",
    "x,y = create_dataset()\n",
    "print(x.shape,y.shape)\n",
    "disp_x,disp_y = devectorize_example(x[0],y[0])\n",
    "print(disp_x)\n",
    "print(disp_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.61 _ 0.62 _ 0.63 _ 0.64 _ 0.63 _ 0.65 _ 0.65 _ 0.66 _ 0.66 _ 0.67 _ 0.68 _ 0.68 _ 0.68 _ 0.69 _ 0.69 _ 0.71 _ 0.70 _ 0.71 _ 0.72 _ 0.72 _ 0.72 _ 0.72 _ 0.73 _ 0.73 _ 0.73 _ 0.74 _ 0.75 _ 0.74 _ 0.75 _ 0.75 _ 0.75 _ 0.75 _ 0.74 _ 0.76 _ 0.77 _ 0.76 _ 0.77 _ 0.77 _ 0.77 _ 0.78 _ 0.78 _ 0.79 _ 0.79 _ 0.80 _ 0.79 _ 0.80 _ 0.81 _ 0.81 _ 0.81 _ 0.81 _ 0.83 _ 0.83 _ 0.83 _ 0.83 _ 0.84 _ 0.85 _ 0.85 _ 0.86 _ 0.86 _ 0.86 _ 0.86 _ 0.87 _ 0.87 _ 0.87 _ 0.87 _ 0.86 _ 0.87 _ 0.88 _ 0.88 _ 0.88 _ 0.89 _ 0.89 _ 0.89 _ 0.90 _ 0.89 _ 0.90 _ 0.90 _ 0.90 _ 0.90 _ 0.90 _ 0.90 _ 0.90 _ 0.91 _ 0.91 _ 0.91 _ 0.92 _ 0.92 _ 0.92 _ 0.92 _ 0.92 _ 0.91 _ 0.93 _ 0.92 _ 0.92 _ 0.93 _ 0.93 _ 0.93 _ 0.93 _ 0.93 _ 0.92 _ 0.93 _ 0.93 _ 0.93 _ 0.94 _ 0.93 _ 0.94 _ 0.94 _ 0.94 _ 0.94 _ 0.94 _ 0.93 _ 0.94 _ 0.94 _ 0.94 _ 0.94 _ 0.94 _ 0.94 _ 0.95 _ 0.94 _ 0.94 _ 0.94 _ 0.95 _ 0.95 _ 0.95 _ 0.94 _ 0.94 _ 0.94 _ 0.95 _ 0.95 _ 0.95 _ 0.95 _ 0.95 _ 0.95 _ 0.95 _ 0.95 _ 0.95 _ 0.95 _ 0.95 _ 0.95 _ 0.95 _ 0.95 _ 0.95 _ 0.95 _ 0.95 _ 0.95 _ 0.95 _ 0.95 _ 0.95 _ 0.96 _ 0.96 _ 0.95 _ 0.95 _ 0.96 _ 0.95 _ 0.96 _ 0.95 _ 0.95 _ 0.96 _ 0.96 _ 0.95 _ 0.96 _ 0.96 _ 0.96 _ 0.96 _ 0.95 _ 0.96 _ 0.96 _ 0.96 _ 0.96 _ "
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x274a9e48788>"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#now we train the model.\n",
    "l_cb = LambdaCallback(on_epoch_end = lambda e,l : print('{:.2f}'.format(l['val_accuracy']),end=\" _ \"))\n",
    "es_cb = EarlyStopping(monitor='val_loss', patience = 10)\n",
    "model.fit(x,y,epochs = 500, batch_size = 256, validation_split = 0.2, verbose = False, callbacks=[es_cb,l_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'create_dataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-5ed3ed4ae1fc>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#let's try on a test set...\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mx_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcreate_dataset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m15\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mpredictions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpred\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'create_dataset' is not defined"
     ]
    }
   ],
   "source": [
    "#let's try on a test set...\n",
    "x_test, y_test = create_dataset(15)\n",
    "predictions = model.predict(x_test)\n",
    "\n",
    "for i, pred in enumerate(predictions):\n",
    "    pred_str = devectorize_example(pred)\n",
    "    y_test_str = devectorize_example(y_test[i])\n",
    "    x_test_str = devectorize_example(x_test[i])\n",
    "    col = 'green' if pred_str == y_test_str else 'red'\n",
    "    outstring = 'Input: {}, Out: {}, Pred: {}'.format(x_test_str, y_test_str, pred_str)\n",
    "    print(colored(outstring, col))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
